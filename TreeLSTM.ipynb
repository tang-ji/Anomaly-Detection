{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.activations import softplus\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "import pydotplus\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class surrogate(object):\n",
    "    def __init__(self, in_count, out_count):\n",
    "        input1 = Input((in_count, ), dtype='float32')\n",
    "        X = input1\n",
    "        for i in range(3):\n",
    "            X = Dense(50, activation='tanh')(X)\n",
    "        output1 = Dense(out_count, activation='softplus')(X)\n",
    "        self.model = Model(inputs=input1, outputs=output1)\n",
    "        self.model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['mean_squared_error'])\n",
    "        self.in_count = in_count\n",
    "        self.out_count = out_count\n",
    "\n",
    "    def train(self, X_train, y_train, batch_size=1, epochs=10):\n",
    "        self.model.fit(X_train, y_train, batch_size = batch_size, epochs = epochs, verbose=1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "\n",
    "def make_graph_minimal(graph,fs):\n",
    "    nodes = graph.get_nodes()\n",
    "    print(\"number of nodes: \" + str(len(nodes)))\n",
    "    for node in nodes:\n",
    "        old_label = node.get_label()\n",
    "        label = prune_label(old_label,fs)\n",
    "        if label is not None:\n",
    "            node.set_label(label)\n",
    "    return graph, len(nodes)\n",
    "\n",
    "\n",
    "def prune_label(label,fs):\n",
    "    if label is None:\n",
    "        return None\n",
    "    if len(label) == 0:\n",
    "        return None\n",
    "    label = label[1:-1]\n",
    "    splitted_label = label.split('\\\\n')\n",
    "    parts = [part for part in splitted_label\n",
    "             if 'gini =' not in part]\n",
    "    return '\"' + '\\\\n'.join(parts) + '\"'\n",
    "\n",
    "def visualize(tree, save_path, fs, feature_names=None, class_names=None):\n",
    "    dot_data = export_graphviz(tree, out_file=None, proportion=True,\n",
    "                               filled=True, rounded=False,class_names=class_names, feature_names=feature_names)\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "    graph, nodes = make_graph_minimal(graph,fs)  # remove extra text\n",
    "\n",
    "    if not save_path is None:\n",
    "        graph.write_pdf(save_path)\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM(object):\n",
    "    def __init__(self, n_steps, n_features, hidden_sizes, out_count):\n",
    "#         input1 = Input((, n_steps, n_features), dtype='float32')\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(32, return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "        model.add(GlobalMaxPooling1D)\n",
    "        model.add(Dense(out_count, activation='softmax'))\n",
    "#         for i in hidden_sizes:\n",
    "#             X = Dense(i, activation='sigmoid')(X)\n",
    "#         X = Dense(out_count, activation='softmax')(X)\n",
    "        self.model = model\n",
    "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        self.num_weights = len([i for l in self.model.get_weights() for i in l.flatten()])\n",
    "        self.in_count = in_count\n",
    "        self.out_count = out_count\n",
    "        self.saved_weights = None\n",
    "        self.last_loss = 0.0\n",
    "\n",
    "    def fit_tree(self, X_train, y_train):\n",
    "        \"\"\"Train decision tree to track path length.\"\"\"\n",
    "        y_train_hat = self.model.predict(X_train)\n",
    "        # y_train_hat_int = np.rint(y_train_hat).astype(int)\n",
    "        y_pred = [np.argmax(x) for x in y_train_hat]\n",
    "        self.tree = DecisionTreeClassifier(min_samples_leaf=1)\n",
    "        self.tree.fit(X_train, y_pred)\n",
    "        return self.tree\n",
    "\n",
    "    def average_path_length(self, X_train, y_train):\n",
    "        tree = self.fit_tree(X_train, y_train)\n",
    "\n",
    "        #Compute average path length\n",
    "        X = X_train\n",
    "        leaf_indices = tree.apply(X)\n",
    "        leaf_counts = np.bincount(leaf_indices)\n",
    "        leaf_i = np.arange(tree.tree_.node_count)\n",
    "        path_length = np.dot(leaf_i, leaf_counts) / float(X.shape[0])\n",
    "\n",
    "        return path_length\n",
    "\n",
    "    def train(self, X_train, y_train, batch_size=128, epochs=2, validation_data=None):\n",
    "        num = min(len(X_train) // batch_size, 30)\n",
    "        self.saved_weights = np.zeros((num, self.num_weights))\n",
    "        self.saved_apl = np.zeros(num)\n",
    "        class AplHistory(keras.callbacks.Callback):\n",
    "            def __init__(self, mlp):\n",
    "                self.mlp = mlp\n",
    "                self.step = 0\n",
    "                self.log = 0\n",
    "                self.epochs = 0\n",
    "            def on_batch_end(self, batch, logs={}):\n",
    "                if self.log < len(self.mlp.saved_apl) and self.epochs == epochs - 1:\n",
    "                    apl = self.mlp.average_path_length(X_train, y_train)\n",
    "                    self.mlp.saved_weights[self.log, :] = [i for l in self.mlp.model.get_weights() for i in l.flatten()]\n",
    "                    self.mlp.saved_apl[self.log] = apl\n",
    "                    self.mlp.last_loss = apl\n",
    "                    self.log += 1\n",
    "                    print(' APL:{:.2f}'.format(apl))\n",
    "                self.step += 1\n",
    "            def on_epoch_end(self, batch, logs={}):\n",
    "                self.epochs += 1\n",
    "\n",
    "        self.model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=[AplHistory(self)], validation_data=validation_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TreeLSTM(object):\n",
    "    def __init__(self, in_features, out_count, hidden_sizes, strength=0.01):\n",
    "        self.mlp = MLP(in_count, hidden_sizes, out_count)\n",
    "        self.sur = surrogate(self.mlp.num_weights, 1)\n",
    "        self.strength = strength\n",
    "        self.tree = []\n",
    "\n",
    "    def loss(self, y_true,y_pred):    \n",
    "        path_length = self.sur.predict(np.array([[i for l in self.mlp.model.get_weights() for i in l.flatten()]])).ravel()[0]\n",
    "        return binary_crossentropy(y_true,y_pred) + self.strength * path_length\n",
    "\n",
    "\n",
    "    def train(self, X_train, y_train, iters_retrain=5, epochs_mlp=3, epochs_sur=5, batch_size=256, feature_names=None, validation_data=None, class_names=None):\n",
    "        for i in range(iters_retrain):\n",
    "            self.mlp.model.compile(optimizer='adam', loss=self.loss, metrics=['accuracy'])\n",
    "            print('training MLP net... [%d/%d]' % (i + 1, iters_retrain))\n",
    "            self.mlp.train(X_train, y_train, epochs=epochs_mlp, batch_size=batch_size, validation_data=validation_data)\n",
    "            print('training surrogate net... [%d/%d]' % (i + 1, iters_retrain))\n",
    "            self.sur.train(self.mlp.saved_weights, self.mlp.saved_apl, batch_size=1, epochs=epochs_sur)\n",
    "            self.tree.append(self.mlp.fit_tree(X_train, y_train))\n",
    "            if not os.path.isdir('./tree'):\n",
    "                os.mkdir('./tree')\n",
    "            nodes = visualize(self.tree[-1], './tree/tree' + str(i) + '.pdf',False,feature_names, class_names)\n",
    "            acc = accuracy_score([np.argmax(x) for x in self.mlp.predict(validation_data[0])], [np.argmax(x) for x in validation_data[1]])\n",
    "            log = open('./tree/log.txt', 'a')\n",
    "            log.write('tree'+ str(i) + ': accuracy {:.5f}; number of nodes '.format(acc) + str(nodes) + '\\n')\n",
    "            log.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "csv_n = pd.read_csv('normal_benchmark_userclicks_1_18_10000_1000000_batch146_20_.csv').iloc[:, 1:].fillna(value = 0)\n",
    "csv_an = pd.read_csv('abnormal_benchmark_userclicks_1_18_10000_1000000_batch146_20_.csv').iloc[:, 1:].fillna(value = 0)\n",
    "csv_an = csv_an.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat((csv_n, csv_an))\n",
    "df = df.sample(frac=1)\n",
    "from sklearn import model_selection\n",
    "df = df.fillna(value = 0)\n",
    "\n",
    "X = df.drop(['label'], axis=1)\n",
    "# normalization\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "Y = np.array(df['label'])\n",
    "train_index, test_index = model_selection.train_test_split(list(range(len(X))), test_size=0.2, random_state=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
