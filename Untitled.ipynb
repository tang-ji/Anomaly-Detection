{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "csv_n = pd.read_csv('normal_benchmark_userclicks_1_18_10000_1000000_batch146_20_.csv').iloc[:, 1:].fillna(value = 0)\n",
    "csv_an = pd.read_csv('abnormal_benchmark_userclicks_1_18_10000_1000000_batch146_20_.csv').iloc[:, 1:].fillna(value = 0)\n",
    "csv_an = csv_an.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat((csv_n, csv_an))\n",
    "df = df.sample(frac=1)\n",
    "from sklearn import model_selection\n",
    "df = df.fillna(value = 0)\n",
    "\n",
    "X = df.drop(['label'], axis=1)\n",
    "# normalization\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "Y = np.array(df['label'])\n",
    "train_index, test_index = model_selection.train_test_split(list(range(len(X))), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from train import *\n",
    "feature_names = list(df.columns.values)[:-1]\n",
    "t = TreeMLP(X.shape[1], 1, [10, 100, 100], strength=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training MLP net... [1/5]\n",
      "Train on 34469 samples, validate on 8618 samples\n",
      "Epoch 1/3\n",
      "34469/34469 [==============================] - 3s 83us/step - loss: 0.7258 - acc: 0.9992 - val_loss: 0.7246 - val_acc: 0.9995\n",
      "Epoch 2/3\n",
      "34469/34469 [==============================] - 1s 38us/step - loss: 0.7249 - acc: 0.9996 - val_loss: 0.7241 - val_acc: 0.9997\n",
      "Epoch 3/3\n",
      "  256/34469 [..............................] - ETA: 1s - loss: 0.7233 - acc: 1.0000 APL:5.70\n",
      "  512/34469 [..............................] - ETA: 10:42 - loss: 0.7233 - acc: 1.0000 APL:7.36\n",
      "  768/34469 [..............................] - ETA: 16:18 - loss: 0.7233 - acc: 1.0000 APL:8.11\n",
      " 1024/34469 [..............................] - ETA: 18:07 - loss: 0.7235 - acc: 1.0000 APL:8.87\n",
      " 1280/34469 [>.............................] - ETA: 19:24 - loss: 0.7234 - acc: 1.0000 APL:8.05\n",
      " 1536/34469 [>.............................] - ETA: 20:21 - loss: 0.7234 - acc: 1.0000 APL:8.11\n",
      " 1792/34469 [>.............................] - ETA: 20:39 - loss: 0.7234 - acc: 1.0000 APL:8.87\n",
      " 2048/34469 [>.............................] - ETA: 20:50 - loss: 0.7234 - acc: 1.0000 APL:8.05\n",
      " 2304/34469 [=>............................] - ETA: 20:51 - loss: 0.7238 - acc: 0.9996 APL:8.07\n",
      " 2560/34469 [=>............................] - ETA: 20:49 - loss: 0.7238 - acc: 0.9996 APL:6.40\n",
      " 2816/34469 [=>............................] - ETA: 20:26 - loss: 0.7237 - acc: 0.9996 APL:6.46\n",
      " 3072/34469 [=>............................] - ETA: 20:05 - loss: 0.7237 - acc: 0.9997 APL:5.52\n",
      " 3328/34469 [=>............................] - ETA: 19:28 - loss: 0.7237 - acc: 0.9997 APL:5.58\n",
      " 3584/34469 [==>...........................] - ETA: 18:58 - loss: 0.7237 - acc: 0.9997 APL:5.52\n",
      " 3840/34469 [==>...........................] - ETA: 18:37 - loss: 0.7238 - acc: 0.9997 APL:5.52\n",
      " 4096/34469 [==>...........................] - ETA: 18:13 - loss: 0.7238 - acc: 0.9998 APL:4.77\n",
      " 4352/34469 [==>...........................] - ETA: 17:52 - loss: 0.7238 - acc: 0.9998 APL:6.40\n",
      " 4608/34469 [===>..........................] - ETA: 17:47 - loss: 0.7237 - acc: 0.9998 APL:7.25\n",
      " 4864/34469 [===>..........................] - ETA: 17:39 - loss: 0.7237 - acc: 0.9998 APL:6.46\n",
      " 5120/34469 [===>..........................] - ETA: 17:28 - loss: 0.7237 - acc: 0.9998 APL:7.25\n",
      "34469/34469 [==============================] - 193s 6ms/step - loss: 0.7255 - acc: 0.9992 - val_loss: 0.7266 - val_acc: 0.9990\n",
      "training surrogate net... [1/5]\n",
      "Epoch 1/9\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2.9250 - mean_squared_error: 1.5706\n",
      "Epoch 2/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 2.8375 - mean_squared_error: 1.4838\n",
      "Epoch 3/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 2.8267 - mean_squared_error: 1.4735\n",
      "Epoch 4/9\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2.8249 - mean_squared_error: 1.4723\n",
      "Epoch 5/9\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2.8242 - mean_squared_error: 1.4721\n",
      "Epoch 6/9\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2.8236 - mean_squared_error: 1.4721\n",
      "Epoch 7/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 2.8231 - mean_squared_error: 1.4721\n",
      "Epoch 8/9\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2.8225 - mean_squared_error: 1.4721\n",
      "Epoch 9/9\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2.8220 - mean_squared_error: 1.4721\n",
      "number of nodes: 12\n",
      "training MLP net... [2/5]\n",
      "Train on 34469 samples, validate on 8618 samples\n",
      "Epoch 1/3\n",
      "34469/34469 [==============================] - 2s 65us/step - loss: 0.6930 - acc: 0.9996 - val_loss: 0.6925 - val_acc: 0.9995\n",
      "Epoch 2/3\n",
      "34469/34469 [==============================] - 1s 43us/step - loss: 0.6928 - acc: 0.9997 - val_loss: 0.6920 - val_acc: 1.0000\n",
      "Epoch 3/3\n",
      "  256/34469 [..............................] - ETA: 1s - loss: 0.6919 - acc: 1.0000 APL:5.58\n",
      "  512/34469 [..............................] - ETA: 7:58 - loss: 0.6918 - acc: 1.0000 APL:5.52\n",
      "  768/34469 [..............................] - ETA: 10:14 - loss: 0.6921 - acc: 1.0000 APL:5.52\n",
      " 1024/34469 [..............................] - ETA: 11:24 - loss: 0.6920 - acc: 1.0000 APL:5.58\n",
      " 1280/34469 [>.............................] - ETA: 11:59 - loss: 0.6920 - acc: 1.0000 APL:5.52\n",
      " 1536/34469 [>.............................] - ETA: 12:23 - loss: 0.6919 - acc: 1.0000 APL:3.61\n",
      " 1792/34469 [>.............................] - ETA: 12:36 - loss: 0.6919 - acc: 1.0000 APL:3.61\n",
      " 2048/34469 [>.............................] - ETA: 12:58 - loss: 0.6919 - acc: 1.0000 APL:3.61\n",
      " 2304/34469 [=>............................] - ETA: 13:00 - loss: 0.6919 - acc: 1.0000 APL:3.61\n",
      " 2560/34469 [=>............................] - ETA: 13:01 - loss: 0.6919 - acc: 1.0000 APL:3.61\n",
      " 2816/34469 [=>............................] - ETA: 13:06 - loss: 0.6919 - acc: 1.0000 APL:3.61\n",
      " 3072/34469 [=>............................] - ETA: 13:02 - loss: 0.6919 - acc: 1.0000 APL:5.28\n",
      " 3328/34469 [=>............................] - ETA: 13:15 - loss: 0.6918 - acc: 1.0000 APL:5.28\n",
      " 3584/34469 [==>...........................] - ETA: 13:29 - loss: 0.6918 - acc: 1.0000 APL:5.28\n",
      " 3840/34469 [==>...........................] - ETA: 13:39 - loss: 0.6918 - acc: 1.0000 APL:5.28\n",
      " 4096/34469 [==>...........................] - ETA: 13:47 - loss: 0.6918 - acc: 1.0000 APL:5.28\n",
      " 4352/34469 [==>...........................] - ETA: 13:53 - loss: 0.6918 - acc: 1.0000 APL:5.28\n",
      " 4608/34469 [===>..........................] - ETA: 13:57 - loss: 0.6918 - acc: 1.0000 APL:5.28\n",
      " 4864/34469 [===>..........................] - ETA: 13:59 - loss: 0.6918 - acc: 1.0000 APL:5.28\n",
      " 5120/34469 [===>..........................] - ETA: 14:01 - loss: 0.6918 - acc: 1.0000 APL:5.28\n",
      "34469/34469 [==============================] - 157s 5ms/step - loss: 0.6920 - acc: 0.9999 - val_loss: 0.6918 - val_acc: 1.0000\n",
      "training surrogate net... [2/5]\n",
      "Epoch 1/9\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 6.3000 - mean_squared_error: 4.9507\n",
      "Epoch 2/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 2.5713 - mean_squared_error: 1.2232\n",
      "Epoch 3/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 2.0975 - mean_squared_error: 0.7502\n",
      "Epoch 4/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 2.0250 - mean_squared_error: 0.6783\n",
      "Epoch 5/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 2.0130 - mean_squared_error: 0.6669\n",
      "Epoch 6/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 2.0106 - mean_squared_error: 0.6651\n",
      "Epoch 7/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 2.0098 - mean_squared_error: 0.6648\n",
      "Epoch 8/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 2.0092 - mean_squared_error: 0.6647\n",
      "Epoch 9/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 2.0087 - mean_squared_error: 0.6647\n",
      "number of nodes: 6\n",
      "training MLP net... [3/5]\n",
      "Train on 34469 samples, validate on 8618 samples\n",
      "Epoch 1/3\n",
      "34469/34469 [==============================] - 3s 91us/step - loss: 0.4855 - acc: 0.9997 - val_loss: 0.4848 - val_acc: 1.0000\n",
      "Epoch 2/3\n",
      "34469/34469 [==============================] - 1s 40us/step - loss: 0.4862 - acc: 0.9996 - val_loss: 0.4851 - val_acc: 0.9999\n",
      "Epoch 3/3\n",
      "  256/34469 [..............................] - ETA: 1s - loss: 0.4847 - acc: 1.0000 APL:5.52\n",
      "  512/34469 [..............................] - ETA: 10:43 - loss: 0.4847 - acc: 1.0000 APL:5.52\n",
      "  768/34469 [..............................] - ETA: 13:11 - loss: 0.4847 - acc: 1.0000 APL:5.52\n",
      " 1024/34469 [..............................] - ETA: 14:00 - loss: 0.4848 - acc: 1.0000 APL:4.70\n",
      " 1280/34469 [>.............................] - ETA: 14:06 - loss: 0.4848 - acc: 1.0000 APL:4.76\n",
      " 1536/34469 [>.............................] - ETA: 13:59 - loss: 0.4848 - acc: 1.0000 APL:5.58\n",
      " 1792/34469 [>.............................] - ETA: 13:56 - loss: 0.4850 - acc: 1.0000 APL:4.76\n",
      " 2048/34469 [>.............................] - ETA: 14:04 - loss: 0.4851 - acc: 1.0000 APL:5.52\n",
      " 2304/34469 [=>............................] - ETA: 14:17 - loss: 0.4851 - acc: 1.0000 APL:4.76\n",
      " 2560/34469 [=>............................] - ETA: 14:21 - loss: 0.4851 - acc: 1.0000 APL:5.58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2816/34469 [=>............................] - ETA: 14:16 - loss: 0.4852 - acc: 1.0000 APL:5.58\n",
      " 3072/34469 [=>............................] - ETA: 14:09 - loss: 0.4851 - acc: 1.0000 APL:5.58\n",
      " 3328/34469 [=>............................] - ETA: 14:02 - loss: 0.4851 - acc: 1.0000 APL:5.52\n",
      " 3584/34469 [==>...........................] - ETA: 13:52 - loss: 0.4851 - acc: 1.0000 APL:5.58\n",
      " 3840/34469 [==>...........................] - ETA: 13:49 - loss: 0.4851 - acc: 1.0000 APL:5.58\n",
      " 4096/34469 [==>...........................] - ETA: 13:42 - loss: 0.4850 - acc: 1.0000 APL:5.52\n",
      " 4352/34469 [==>...........................] - ETA: 13:36 - loss: 0.4852 - acc: 0.9998 APL:4.49\n",
      " 4608/34469 [===>..........................] - ETA: 13:44 - loss: 0.4852 - acc: 0.9998 APL:5.29\n",
      " 4864/34469 [===>..........................] - ETA: 13:52 - loss: 0.4852 - acc: 0.9998 APL:5.29\n",
      " 5120/34469 [===>..........................] - ETA: 14:00 - loss: 0.4852 - acc: 0.9998 APL:6.14\n",
      "34469/34469 [==============================] - 158s 5ms/step - loss: 0.4850 - acc: 0.9999 - val_loss: 0.4847 - val_acc: 1.0000\n",
      "training surrogate net... [3/5]\n",
      "Epoch 1/9\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.7541 - mean_squared_error: 0.4107\n",
      "Epoch 2/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.5497 - mean_squared_error: 0.2067\n",
      "Epoch 3/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.5157 - mean_squared_error: 0.1732\n",
      "Epoch 4/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.5099 - mean_squared_error: 0.1679\n",
      "Epoch 5/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.5085 - mean_squared_error: 0.1671\n",
      "Epoch 6/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.5079 - mean_squared_error: 0.1669\n",
      "Epoch 7/9\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.5073 - mean_squared_error: 0.1669\n",
      "Epoch 8/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.5068 - mean_squared_error: 0.1669\n",
      "Epoch 9/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.5062 - mean_squared_error: 0.1669\n",
      "number of nodes: 4\n",
      "training MLP net... [4/5]\n",
      "Train on 34469 samples, validate on 8618 samples\n",
      "Epoch 1/3\n",
      "34469/34469 [==============================] - 2s 67us/step - loss: 0.5346 - acc: 0.9998 - val_loss: 0.5342 - val_acc: 0.9998\n",
      "Epoch 2/3\n",
      "34469/34469 [==============================] - 1s 42us/step - loss: 0.5342 - acc: 1.0000 - val_loss: 0.5340 - val_acc: 1.0000\n",
      "Epoch 3/3\n",
      "  256/34469 [..............................] - ETA: 1s - loss: 0.5340 - acc: 1.0000 APL:1.88\n",
      "  512/34469 [..............................] - ETA: 5:22 - loss: 0.5340 - acc: 1.0000 APL:1.88\n",
      "  768/34469 [..............................] - ETA: 6:59 - loss: 0.5340 - acc: 1.0000 APL:1.88\n",
      " 1024/34469 [..............................] - ETA: 8:06 - loss: 0.5340 - acc: 1.0000 APL:1.88\n",
      " 1280/34469 [>.............................] - ETA: 8:31 - loss: 0.5340 - acc: 1.0000 APL:1.88\n",
      " 1536/34469 [>.............................] - ETA: 8:59 - loss: 0.5340 - acc: 1.0000 APL:1.88\n",
      " 1792/34469 [>.............................] - ETA: 9:12 - loss: 0.5340 - acc: 1.0000 APL:1.88\n",
      " 2048/34469 [>.............................] - ETA: 9:27 - loss: 0.5340 - acc: 1.0000 APL:1.88\n",
      " 2304/34469 [=>............................] - ETA: 9:38 - loss: 0.5340 - acc: 1.0000 APL:1.88\n",
      " 2560/34469 [=>............................] - ETA: 9:45 - loss: 0.5340 - acc: 1.0000 APL:1.88\n",
      " 2816/34469 [=>............................] - ETA: 9:40 - loss: 0.5340 - acc: 1.0000 APL:1.88\n",
      " 3072/34469 [=>............................] - ETA: 9:33 - loss: 0.5340 - acc: 1.0000 APL:1.88\n",
      " 3328/34469 [=>............................] - ETA: 9:26 - loss: 0.5340 - acc: 1.0000 APL:1.88\n",
      " 3584/34469 [==>...........................] - ETA: 9:23 - loss: 0.5340 - acc: 1.0000 APL:1.88\n",
      " 3840/34469 [==>...........................] - ETA: 9:23 - loss: 0.5340 - acc: 1.0000 APL:1.88\n",
      " 4096/34469 [==>...........................] - ETA: 9:17 - loss: 0.5340 - acc: 1.0000 APL:1.88\n",
      " 4352/34469 [==>...........................] - ETA: 9:10 - loss: 0.5340 - acc: 1.0000 APL:1.88\n",
      " 4608/34469 [===>..........................] - ETA: 9:06 - loss: 0.5340 - acc: 1.0000 APL:1.88\n",
      " 4864/34469 [===>..........................] - ETA: 9:02 - loss: 0.5340 - acc: 1.0000 APL:1.88\n",
      " 5120/34469 [===>..........................] - ETA: 8:58 - loss: 0.5340 - acc: 1.0000 APL:1.88\n",
      "34469/34469 [==============================] - 100s 3ms/step - loss: 0.5340 - acc: 1.0000 - val_loss: 0.5340 - val_acc: 1.0000\n",
      "training surrogate net... [4/5]\n",
      "Epoch 1/9\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 13.3045 - mean_squared_error: 11.9657\n",
      "Epoch 2/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 3.3481 - mean_squared_error: 2.0106\n",
      "Epoch 3/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.7985 - mean_squared_error: 0.4617\n",
      "Epoch 4/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.4644 - mean_squared_error: 0.1283\n",
      "Epoch 5/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.3754 - mean_squared_error: 0.0398\n",
      "Epoch 6/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.3481 - mean_squared_error: 0.0131\n",
      "Epoch 7/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.3389 - mean_squared_error: 0.0045\n",
      "Epoch 8/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.3355 - mean_squared_error: 0.0016\n",
      "Epoch 9/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.3339 - mean_squared_error: 5.4755e-04\n",
      "number of nodes: 4\n",
      "training MLP net... [5/5]\n",
      "Train on 34469 samples, validate on 8618 samples\n",
      "Epoch 1/3\n",
      "34469/34469 [==============================] - 2s 66us/step - loss: 0.1902 - acc: 0.9999 - val_loss: 0.1909 - val_acc: 0.9995\n",
      "Epoch 2/3\n",
      "34469/34469 [==============================] - 1s 41us/step - loss: 0.1904 - acc: 0.9997 - val_loss: 0.1895 - val_acc: 1.0000\n",
      "Epoch 3/3\n",
      "  256/34469 [..............................] - ETA: 1s - loss: 0.1894 - acc: 1.0000 APL:1.88\n",
      "  512/34469 [..............................] - ETA: 5:16 - loss: 0.1895 - acc: 1.0000 APL:1.88\n",
      "  768/34469 [..............................] - ETA: 6:52 - loss: 0.1895 - acc: 1.0000 APL:1.88\n",
      " 1024/34469 [..............................] - ETA: 7:38 - loss: 0.1895 - acc: 1.0000 APL:1.88\n",
      " 1280/34469 [>.............................] - ETA: 8:37 - loss: 0.1895 - acc: 1.0000 APL:1.88\n",
      " 1536/34469 [>.............................] - ETA: 9:09 - loss: 0.1895 - acc: 1.0000 APL:1.88\n",
      " 1792/34469 [>.............................] - ETA: 9:45 - loss: 0.1895 - acc: 1.0000 APL:1.88\n",
      " 2048/34469 [>.............................] - ETA: 10:10 - loss: 0.1895 - acc: 1.0000 APL:1.88\n",
      " 2304/34469 [=>............................] - ETA: 10:11 - loss: 0.1895 - acc: 1.0000 APL:1.88\n",
      " 2560/34469 [=>............................] - ETA: 10:08 - loss: 0.1895 - acc: 1.0000 APL:1.88\n",
      " 2816/34469 [=>............................] - ETA: 10:02 - loss: 0.1895 - acc: 1.0000 APL:1.88\n",
      " 3072/34469 [=>............................] - ETA: 9:58 - loss: 0.1895 - acc: 1.0000  APL:1.88\n",
      " 3328/34469 [=>............................] - ETA: 9:53 - loss: 0.1895 - acc: 1.0000 APL:1.88\n",
      " 3584/34469 [==>...........................] - ETA: 9:49 - loss: 0.1895 - acc: 1.0000 APL:1.88\n",
      " 3840/34469 [==>...........................] - ETA: 9:44 - loss: 0.1895 - acc: 1.0000 APL:1.88\n",
      " 4096/34469 [==>...........................] - ETA: 9:42 - loss: 0.1895 - acc: 1.0000 APL:1.88\n",
      " 4352/34469 [==>...........................] - ETA: 9:35 - loss: 0.1895 - acc: 1.0000 APL:1.88\n",
      " 4608/34469 [===>..........................] - ETA: 9:28 - loss: 0.1895 - acc: 1.0000 APL:1.88\n",
      " 4864/34469 [===>..........................] - ETA: 9:24 - loss: 0.1895 - acc: 1.0000 APL:1.88\n",
      " 5120/34469 [===>..........................] - ETA: 9:19 - loss: 0.1895 - acc: 1.0000 APL:1.88\n",
      "34469/34469 [==============================] - 104s 3ms/step - loss: 0.1895 - acc: 1.0000 - val_loss: 0.1895 - val_acc: 1.0000\n",
      "training surrogate net... [5/5]\n",
      "Epoch 1/9\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.3330 - mean_squared_error: 1.9156e-04\n",
      "Epoch 2/9\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.3324 - mean_squared_error: 6.7689e-05\n",
      "Epoch 3/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.3318 - mean_squared_error: 2.3813e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.3313 - mean_squared_error: 8.2924e-06\n",
      "Epoch 5/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.3307 - mean_squared_error: 2.8321e-06\n",
      "Epoch 6/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.3302 - mean_squared_error: 9.3376e-07\n",
      "Epoch 7/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.3296 - mean_squared_error: 2.8872e-07\n",
      "Epoch 8/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.3291 - mean_squared_error: 7.8446e-08\n",
      "Epoch 9/9\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.3286 - mean_squared_error: 1.5928e-08\n",
      "number of nodes: 4\n"
     ]
    }
   ],
   "source": [
    "t.train(X[train_index], Y[train_index], feature_names=feature_names, validation_data=(X[test_index], Y[test_index]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
